{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python version：3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import linalg\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef, confusion_matrix\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(view1,view2,alpha,sita,num):\n",
    "\n",
    "    MMS = MinMaxScaler()\n",
    "    X1 = MMS.fit_transform(np.matrix(view1.iloc[:,:-1]))\n",
    "    X2 = MMS.fit_transform(np.matrix(view2.iloc[:,:-1]))\n",
    "    y1,y2  = view1.iloc[:,-1],view2.iloc[:,-1]\n",
    "    \n",
    "    MMSdata1=pd.DataFrame(np.column_stack((X1,y1)))\n",
    "    MMSdata2=pd.DataFrame(np.column_stack((X2,y2)))\n",
    "    \n",
    "    # Distinguish between positive and negative labeled samples\n",
    "    PM1=np.matrix(MMSdata1[MMSdata1.iloc[:,-1]==1])[:,:-1]  \n",
    "    NM1=np.matrix(MMSdata1[MMSdata1.iloc[:,-1]==-1])[:,:-1]  \n",
    "    \n",
    "    PM2=np.matrix(MMSdata2[MMSdata2.iloc[:,-1]==1])[:,:-1]   \n",
    "    NM2=np.matrix(MMSdata2[MMSdata2.iloc[:,-1]==-1])[:,:-1] \n",
    "    \n",
    "    n,n1,n2= X1.shape[0] ,PM1.shape[0] ,NM1.shape[0]  \n",
    "    \n",
    "    # Positive_S matrix and negative_S matrix\n",
    "    MA1,MA2 = PM1-(np.matrix(np.ones(n1))).T@pu1,PM2-(np.matrix(np.ones(n1))).T@pu2\n",
    "    MB1,MB2 = NM1-(np.matrix(np.ones(n2))).T@nu1,NM2-(np.matrix(np.ones(n2))).T@nu2\n",
    "    \n",
    "    PS1,PS2 = MA1.T@MA1,MA2.T@MA2\n",
    "    NS1,NS2 = MB1.T@MB1,MB2.T@MB2\n",
    "\n",
    "    PL1 = (X1-(np.matrix(np.ones(n))).T@pu1).T@(X1-(np.matrix(np.ones(n))).T@pu1) \n",
    "    PL2 = (X2-(np.matrix(np.ones(n))).T@pu2).T@(X2-(np.matrix(np.ones(n))).T@pu2)\n",
    "\n",
    "    NL1 = (X1-(np.matrix(np.ones(n))).T@nu1).T@(X1-(np.matrix(np.ones(n))).T@nu1)\n",
    "    NL2 = (X2-(np.matrix(np.ones(n))).T@nu2).T@(X2-(np.matrix(np.ones(n))).T@nu2)\n",
    "        \n",
    "    positive_matrix1 = (1+sita)*PS1\n",
    "    negative_matrix1 = (1+sita)*NS1\n",
    "    \n",
    "    positive_matrix2 = -sita*MA1.T@ MA2\n",
    "    negative_matrix2 = -sita*MB1.T@ MB2\n",
    "    \n",
    "    positive_goal_matrix1 =  np.concatenate((positive_matrix1,positive_matrix2),axis=1)\n",
    "    negative_goal_matrix1 =  np.concatenate((negative_matrix1,negative_matrix2),axis=1)\n",
    "    \n",
    "    positive_matrix3 = -sita*MA2.T@MA1\n",
    "    negative_matrix3 = -sita*MB2.T@MB1\n",
    "    \n",
    "    positive_matrix4 = (1+ sita)*PS2 \n",
    "    negative_matrix4 = (1+ sita)*NS2  \n",
    "    \n",
    "    positive_goal_matrix2 =  np.concatenate((positive_matrix3,positive_matrix4),axis=1)\n",
    "    negative_goal_matrix2 =  np.concatenate((negative_matrix3,negative_matrix4),axis=1)\n",
    "    \n",
    "    # concatenated matrix\n",
    "    positive_K  =  np.concatenate((positive_goal_matrix1,positive_goal_matrix2),axis=0)\n",
    "    positive_K  =  positive_K + alpha*np.eye(positive_K.shape[0])\n",
    "    negative_K  =  np.concatenate((negative_goal_matrix1,negative_goal_matrix2),axis=0)\n",
    "    negative_K  =  negative_K + alpha*np.eye(negative_K.shape[0])\n",
    "    \n",
    "    positive_L1matrix =  np.concatenate((PL1,np.zeros((PL1.shape[0],PL2.shape[1]))),axis=1)\n",
    "    positive_L2matrix =  np.concatenate((np.zeros((PL2.shape[0],PL1.shape[1])),PL2),axis=1)\n",
    "    positive_T= np.concatenate((positive_L1matrix,positive_L2matrix),axis = 0)\n",
    "    \n",
    "    negative_L1matrix =  np.concatenate((NL1,np.zeros((NL1.shape[0],NL2.shape[1]))),axis=1)\n",
    "    negative_L2matrix =  np.concatenate((np.zeros((NL2.shape[0],NL1.shape[1])),NL2),axis=1)\n",
    "    negative_T= np.concatenate((negative_L1matrix,negative_L2matrix),axis = 0)\n",
    "    \n",
    "    # Obtain the eigenvalues and eigenvectors [w1, w2] of two views\n",
    "    (positive_eva, positive_evt) = sp.linalg.eig(positive_K,positive_T)   \n",
    "    (negative_eva, negative_evt) = sp.linalg.eig(negative_K,negative_T)   \n",
    "    \n",
    "    # Sort from small to large\n",
    "    df_positive=np.column_stack((positive_evt.T,positive_eva))\n",
    "    df_positive=pd.DataFrame(df_positive)\n",
    "    df_positive=df_positive.sort_values(by=df_positive.columns[-1],ascending=True)\n",
    "    \n",
    "    eva_positive = np.matrix(df_positive.iloc[:num,-1]) \n",
    "    evt_positive = np.matrix(df_positive.iloc[:num,:-1])\n",
    "    \n",
    "\n",
    "    df_negative=np.column_stack((negative_evt.T,negative_eva))\n",
    "    df_negative=pd.DataFrame(df_negative)\n",
    "    df_negative=df_negative.sort_values(by=df_negative.columns[-1],ascending=True)\n",
    "    \n",
    "    eva_negative = np.matrix(df_negative.iloc[:num,-1])  \n",
    "    evt_negative = np.matrix(df_negative.iloc[:num,:-1]) \n",
    "    \n",
    "    evt_positive1 = evt_positive[:,:X1.shape[1]]\n",
    "    evt_positive2 = evt_positive[:,X1.shape[1]:]\n",
    "    \n",
    "    evt_negative1 = evt_negative[:,:X1.shape[1]]\n",
    "    evt_negative2 = evt_negative[:,X1.shape[1]:]\n",
    "    \n",
    "    return  evt_positive1,evt_positive2,evt_negative1,evt_negative2,pu1,pu2,nu1,nu2\n",
    "    \n",
    "    # Calculate acc, f1, mcc, sensitivity, specificity\n",
    "def score(view1,view2,evt_positive1,evt_positive2,evt_negative1,evt_negative2,pu1,pu2,nu1,nu2):\n",
    "    MMS = MinMaxScaler()\n",
    "    X1 = MMS.fit_transform(np.matrix(view1.iloc[:, :-1]))\n",
    "    X2 = MMS.fit_transform(np.matrix(view2.iloc[:, :-1]))\n",
    "    y = list(view1.iloc[:, -1]) \n",
    "    \n",
    "    yp1 = np.linalg.norm(X1 @ evt_positive1.T - pu1 @ evt_positive1.T, axis=1, keepdims=False)\n",
    "    yp2 = np.linalg.norm(X2 @ evt_positive2.T - pu2 @ evt_positive2.T, axis=1, keepdims=False)\n",
    "    yn1 = np.linalg.norm(X1 @ evt_negative1.T - nu1 @ evt_negative1.T, axis=1, keepdims=False)\n",
    "    yn2 = np.linalg.norm(X2 @ evt_negative2.T - nu2 @ evt_negative2.T, axis=1, keepdims=False)\n",
    "    \n",
    "\n",
    "    y_pred = [yn1[i] + yn2[i] - yp1[i] - yp2[i] for i in range(len(yp1))]\n",
    "    y_label = [1 if i >= 0 else -1 for i in y_pred]  \n",
    "    \n",
    "\n",
    "    acc = accuracy_score(y, y_label)\n",
    "    \n",
    "    f1 = f1_score(y, y_label, average='weighted')\n",
    "    \n",
    "    mcc = matthews_corrcoef(y, y_label)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_label, labels=[-1, 1]).ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  \n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  \n",
    "\n",
    "\n",
    "    return acc, f1, mcc, sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 134400/134400 [10:06<00:00, 221.49it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # read data\n",
    "    filename_list = ['cleveland']\n",
    "    n_components  = [8]\n",
    "    \n",
    "    for k in range(len(filename_list)):\n",
    "        view1 = pd.read_csv(filename_list[k]+ '.csv', header=None)\n",
    "        # PCA\n",
    "        modelPCA = PCA(n_components=n_components[k])  \n",
    "        PCAdata = modelPCA.fit_transform(view1.copy().iloc[:, :-1])  \n",
    "        view2 = pd.concat([pd.DataFrame(PCAdata), view1.iloc[:, -1]], axis=1)\n",
    "        \n",
    "        # normalization\n",
    "        MMS = MinMaxScaler()\n",
    "        X1 = np.matrix(MMS.fit_transform(np.matrix(view1.iloc[:,:-1])))\n",
    "        X2 = np.matrix(MMS.fit_transform(np.matrix(view2.iloc[:,:-1])))\n",
    "        y1,y2  = view1.iloc[:,-1],view2.iloc[:,-1]\n",
    "        \n",
    "        data1=pd.DataFrame(np.column_stack((X1,y1)))\n",
    "        data2=pd.DataFrame(np.column_stack((X2,y2)))\n",
    "        \n",
    "        # classification\n",
    "        PM1=np.matrix(data1[data1.iloc[:,-1]==1])[:,:-1]  \n",
    "        NM1=np.matrix(data1[data1.iloc[:,-1]==-1])[:,:-1]  \n",
    "        \n",
    "        PM2=np.matrix(data2[data2.iloc[:,-1]==1])[:,:-1]   \n",
    "        NM2=np.matrix(data2[data2.iloc[:,-1]==-1])[:,:-1]  \n",
    "        \n",
    "        pu1,pu2 = np.sum(PM1,axis=0)/PM1.shape[0],np.sum(PM2,axis=0)/PM2.shape[0]  \n",
    "        nu1,nu2 = np.sum(NM1,axis=0)/NM1.shape[0],np.sum(NM2,axis=0)/NM2.shape[0]  \n",
    "        \n",
    "        # cross validation\n",
    "        kf1 = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "        kf2 = KFold(n_splits=5, shuffle=True, random_state=110)\n",
    "\n",
    "         # Create empty lists, you can use these lists to record the rseults.\n",
    "        result = []\n",
    "        acc_list = []\n",
    "        f1_list = []\n",
    "        mcc_list = []  \n",
    "        sensitivity_list = []  \n",
    "        specificity_list = []  \n",
    "\n",
    "        # Determine the parameter range\n",
    "        alpha_list = [2**i for i in range(-8, 8)]\n",
    "        sita_list  = [2**i for i in range(-8, 8)]\n",
    "        num_list = list(range(1, view1.shape[1] + view2.shape[1] - 1))\n",
    "        \n",
    "        with tqdm(total=len(num_list)*len(sita_list)*len(alpha_list)*25) as pbar:\n",
    "            res = {}           \n",
    "            for num in num_list:\n",
    "                acc_list = []\n",
    "                f1_list = []\n",
    "                mcc_list = []\n",
    "                sensitivity_list = []\n",
    "                specificity_list = []\n",
    "                for train_valid_index, test_index in kf1.split(view1):\n",
    "\n",
    "                    view1_train_valid = view1.iloc[train_valid_index]\n",
    "                    view1_test = view1.iloc[test_index]\n",
    "                    \n",
    "                    view2_train_valid = view2.iloc[train_valid_index]\n",
    "                    view2_test = view2.iloc[test_index]\n",
    "                    \n",
    "                    result_dict = {}\n",
    "                    \n",
    "                    for sita in sita_list:\n",
    "                        for alpha in alpha_list:\n",
    "                            result_list = []\n",
    "                            for train_index, valid_index in kf2.split(view1_train_valid):\n",
    "                                view1_train  =view1.iloc[train_index]\n",
    "                                view1_valid  =view1.iloc[valid_index]\n",
    "                                \n",
    "                                view2_train  =view2.iloc[train_index]\n",
    "                                view2_valid  =view2.iloc[valid_index]\n",
    "                                \n",
    "                                start_time = time.time()\n",
    "                                evt_positive1, evt_positive2, evt_negative1, evt_negative2, pu1, pu2, nu1, nu2 = fit(view1_train, view2_train, alpha, sita, num)\n",
    "                                acc, f1, mcc, sensitivity, specificity = score(view1_valid, view2_valid, evt_positive1, evt_positive2, evt_negative1, evt_negative2, pu1, pu2, nu1, nu2)\n",
    "                                end_time = time.time()\n",
    "\n",
    "                                pbar.update(1)\n",
    "                                result_list.append((acc, f1, mcc, sensitivity, specificity))\n",
    "                                \n",
    "                            acc_mean = np.mean([x[0] for x in result_list])\n",
    "                                \n",
    "                            result_dict[(alpha, sita)] = (acc_mean)\n",
    "                    \n",
    "                    # Select the optimal parameters\n",
    "                    para = sorted(result_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "                    best_alpha = para[0][0][0]\n",
    "                    best_sita = para[0][0][1]\n",
    "                   \n",
    "                    evt_positive1, evt_positive2, evt_negative1, evt_negative2, pu1, pu2, nu1, nu2 = fit(view1_train_valid, view2_train_valid, best_alpha, best_sita, num)\n",
    "                    acc = score(view1_test, view2_test, evt_positive1, evt_positive2, evt_negative1, evt_negative2, pu1, pu2, nu1, nu2)\n",
    "                    acc_list.append(acc)\n",
    "                    \n",
    "                acc_mean, acc_std = np.mean(acc_list), np.std(acc_list)\n",
    "                \n",
    "                res[num] = (acc_mean, acc_std, best_alpha, best_sita)\n",
    "                                                                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009759664535522461\n"
     ]
    }
   ],
   "source": [
    "run_time = end_time - start_time    # record run_time\n",
    "print(run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
